{
    "key_": "nndeploy.dag.Graph",
    "name_": "Face_Swap_GAN_Many_Face",
    "developer_": "Always",
    "source_": "https://github.com/hacksider/Deep-Live-Cam",
    "desc_": "Face swap workflow integrating face swap and GAN(Make faces clearer), supports swapping multiple faces in a single image",
    "device_type_": "kDeviceTypeCodeCpu:0",
    "version_": "1.0.0",
    "required_params_": [],
    "ui_params_": [],
    "is_dynamic_input_": false,
    "inputs_": [],
    "is_dynamic_output_": false,
    "outputs_": [],
    "is_graph_": true,
    "parallel_type_": "kParallelTypeNone",
    "is_inner_": false,
    "node_type_": "Intermediate",
    "is_time_profile_": false,
    "is_debug_": false,
    "is_external_stream_": false,
    "is_graph_node_share_stream_": true,
    "queue_max_size_": 16,
    "is_loop_max_flag_": true,
    "loop_count_": -1,
    "image_url_": [
        "template[http,modelscope]@https://template.cn/template.jpg"
    ],
    "video_url_": [
        "template[http,modelscope]@https://template.cn/template.mp4"
    ],
    "audio_url_": [
        "template[http,modelscope]@https://template.cn/template.mp3"
    ],
    "model_url_": [
        "modelscope@nndeploy/nndeploy:face_swap/inswapper_128_fp16.onnx",
        "modelscope@nndeploy/nndeploy:face_swap/GFPGANv1.4.pth"
    ],
    "other_url_": [
        "template[http,modelscope]@https://template.cn/template.txt"
    ],
    "node_repository_": [
        {
            "key_": "nndeploy.face.InsightFaceAnalysis",
            "name_": "InsightFaceAnalysis_40",
            "developer_": "",
            "source_": "",
            "desc_": "InsightFace Analysis: get face analysis from image",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [],
            "ui_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "type_": "ndarray",
                    "name_": "OpenCvImageDecode_55@output_0"
                }
            ],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "type_": "list[Face]",
                    "name_": "InsightFaceAnalysis_40@output_0"
                }
            ],
            "node_type_": "Intermediate",
            "insightface_name_": "buffalo_l",
            "providers_": [
                "CPUExecutionProvider"
            ],
            "is_one_face_": false,
            "ctx_id": 0,
            "det_thresh_": 0.5,
            "node_repository_": [],
            "size": {
                "width": 200,
                "height": 80
            }
        },
        {
            "key_": "nndeploy.face.InsightImageFaceId",
            "name_": "InsightImageFaceId_42",
            "developer_": "",
            "source_": "",
            "desc_": "InsightFace Id: get face id from image, 人脸排序的规则是[x_min, y_min]，即左上角的人脸来排序",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [],
            "ui_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "type_": "ndarray",
                    "name_": "OpenCvImageDecode_55@output_0"
                },
                {
                    "desc_": "input_1",
                    "type_": "list[Face]",
                    "name_": "InsightFaceAnalysis_40@output_0"
                }
            ],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "type_": "list[Any]",
                    "name_": "InsightImageFaceId_42@output_0"
                }
            ],
            "node_type_": "Intermediate",
            "node_repository_": [],
            "size": {
                "width": 200,
                "height": 80
            }
        },
        {
            "key_": "nndeploy.face.InsightFaceSwapperWithMap",
            "name_": "InsightFaceSwapperWithMap_47",
            "developer_": "",
            "source_": "",
            "desc_": "InsightFace Swapper: swap face from image",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [],
            "ui_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "type_": "ndarray",
                    "name_": "OpenCvImageDecode_55@output_0"
                },
                {
                    "desc_": "input_1",
                    "type_": "dict[str, list]",
                    "name_": "FaceIdMap_48@output_0"
                }
            ],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "type_": "ndarray",
                    "name_": "InsightFaceSwapperWithMap_47@output_0"
                }
            ],
            "node_type_": "Intermediate",
            "mouth_mask_": false,
            "show_mouth_mask_box_": false,
            "mask_down_size_": 0.5,
            "mask_feather_ratio_": 8,
            "mask_size_": 1,
            "model_path_": "resources/models/face_swap/inswapper_128_fp16.onnx",
            "providers_": [
                "CPUExecutionProvider"
            ],
            "node_repository_": [],
            "size": {
                "width": 200,
                "height": 80
            }
        },
        {
            "key_": "nndeploy.face.FaceIdMap",
            "name_": "FaceIdMap_48",
            "developer_": "",
            "source_": "",
            "desc_": "FaceIdMap: map face id from image",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [],
            "ui_params_": [],
            "is_dynamic_input_": true,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "type_": "list[Any]",
                    "name_": "InsightImageFaceId_42@output_0"
                },
                {
                    "desc_": "input_1",
                    "type_": "list[Face]",
                    "name_": "InsightFaceAnalysis_60@output_0"
                },
                {
                    "desc_": "input_2",
                    "type_": "list[Face]",
                    "name_": "InsightFaceAnalysis_61@output_0"
                }
            ],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "type_": "dict[str, list]",
                    "name_": "FaceIdMap_48@output_0"
                }
            ],
            "node_type_": "Intermediate",
            "map_ids_": [
                6,
                7
            ],
            "node_repository_": [],
            "size": {
                "width": 200,
                "height": 80
            }
        },
        {
            "key_": "nndeploy.gan.GFPGAN",
            "name_": "GFPGAN_53",
            "developer_": "",
            "source_": "",
            "desc_": "GFPGAN: Make faces clearer",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [
                "model_path_"
            ],
            "ui_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "type_": "ndarray",
                    "name_": "InsightFaceSwapperWithMap_47@output_0"
                }
            ],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "type_": "ndarray",
                    "name_": "GFPGAN_53@output_0"
                }
            ],
            "node_type_": "Intermediate",
            "model_path_": "resources/models/face_swap/GFPGANv1.4.pth",
            "upscale_": 1,
            "node_repository_": [],
            "size": {
                "width": 200,
                "height": 80
            }
        },
        {
            "key_": "nndeploy::codec::OpenCvImageDecode",
            "name_": "OpenCvImageDecode_55",
            "developer_": "",
            "source_": "",
            "desc_": "Decode image using OpenCV, from image path to cv::Mat, default color space is BGR",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [
                "path_"
            ],
            "ui_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "type_": "ndarray",
                    "name_": "OpenCvImageDecode_55@output_0"
                }
            ],
            "node_type_": "Input",
            "io_type_": "Image",
            "path_": "resources/template/nndeploy-workflow/face_swap/kongfu.jpg",
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": []
        },
        {
            "key_": "nndeploy::codec::OpenCvImageDecode",
            "name_": "OpenCvImageDecode_56",
            "developer_": "",
            "source_": "",
            "desc_": "Decode image using OpenCV, from image path to cv::Mat, default color space is BGR",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [
                "path_"
            ],
            "ui_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "type_": "ndarray",
                    "name_": "OpenCvImageDecode_56@output_0"
                }
            ],
            "node_type_": "Input",
            "io_type_": "Image",
            "path_": "resources/template/nndeploy-workflow/face_swap/musk.jpg",
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": []
        },
        {
            "key_": "nndeploy::codec::OpenCvImageDecode",
            "name_": "OpenCvImageDecode_57",
            "developer_": "",
            "source_": "",
            "desc_": "Decode image using OpenCV, from image path to cv::Mat, default color space is BGR",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [
                "path_"
            ],
            "ui_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "type_": "ndarray",
                    "name_": "OpenCvImageDecode_57@output_0"
                }
            ],
            "node_type_": "Input",
            "io_type_": "Image",
            "path_": "resources/template/nndeploy-workflow/face_swap/speed.png",
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": []
        },
        {
            "key_": "nndeploy::codec::OpenCvImageEncode",
            "name_": "OpenCvImageEncode_58",
            "developer_": "",
            "source_": "",
            "desc_": "Encode image using OpenCV, from cv::Mat to image file, supports common image formats",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [
                "path_"
            ],
            "ui_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "type_": "ndarray",
                    "name_": "InsightFaceSwapperWithMap_47@output_0"
                }
            ],
            "is_dynamic_output_": false,
            "outputs_": [],
            "node_type_": "Output",
            "io_type_": "Image",
            "path_": "resources/images/result.face_swap_manyface.png",
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": []
        },
        {
            "key_": "nndeploy::codec::OpenCvImageEncode",
            "name_": "OpenCvImageEncode_59",
            "developer_": "",
            "source_": "",
            "desc_": "Encode image using OpenCV, from cv::Mat to image file, supports common image formats",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [
                "path_"
            ],
            "ui_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "type_": "ndarray",
                    "name_": "GFPGAN_53@output_0"
                }
            ],
            "is_dynamic_output_": false,
            "outputs_": [],
            "node_type_": "Output",
            "io_type_": "Image",
            "path_": "resources/images/result.face_swap_manyface_gan.png",
            "size": {
                "width": 200,
                "height": 80
            },
            "node_repository_": []
        },
        {
            "key_": "nndeploy.face.InsightFaceAnalysis",
            "name_": "InsightFaceAnalysis_60",
            "developer_": "",
            "source_": "",
            "desc_": "InsightFace Analysis: get face analysis from image",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [],
            "ui_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "type_": "ndarray",
                    "name_": "OpenCvImageDecode_56@output_0"
                }
            ],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "type_": "list[Face]",
                    "name_": "InsightFaceAnalysis_60@output_0"
                }
            ],
            "node_type_": "Intermediate",
            "insightface_name_": "buffalo_l",
            "providers_": [
                "CPUExecutionProvider"
            ],
            "is_one_face_": true,
            "ctx_id": 0,
            "det_thresh_": 0.5,
            "node_repository_": [],
            "size": {
                "width": 200,
                "height": 80
            }
        },
        {
            "key_": "nndeploy.face.InsightFaceAnalysis",
            "name_": "InsightFaceAnalysis_61",
            "developer_": "",
            "source_": "",
            "desc_": "InsightFace Analysis: get face analysis from image",
            "device_type_": "kDeviceTypeCodeCpu:0",
            "version_": "1.0.0",
            "required_params_": [],
            "ui_params_": [],
            "is_dynamic_input_": false,
            "inputs_": [
                {
                    "desc_": "input_0",
                    "type_": "ndarray",
                    "name_": "OpenCvImageDecode_57@output_0"
                }
            ],
            "is_dynamic_output_": false,
            "outputs_": [
                {
                    "desc_": "output_0",
                    "type_": "list[Face]",
                    "name_": "InsightFaceAnalysis_61@output_0"
                }
            ],
            "node_type_": "Intermediate",
            "insightface_name_": "buffalo_l",
            "providers_": [
                "CPUExecutionProvider"
            ],
            "is_one_face_": true,
            "ctx_id": 0,
            "det_thresh_": 0.5,
            "node_repository_": [],
            "size": {
                "width": 200,
                "height": 80
            }
        }
    ],
    "nndeploy_ui_layout": {
        "layout": {
            "InsightFaceAnalysis_40": {
                "x": -835.917163831375,
                "y": -439.4026713855808
            },
            "InsightImageFaceId_42": {
                "x": -524.5810372628291,
                "y": -465.4026713855808
            },
            "InsightFaceSwapperWithMap_47": {
                "x": 46.1409140993149,
                "y": -683.749908825806
            },
            "FaceIdMap_48": {
                "x": -247.059727813276,
                "y": -324.7857632240288
            },
            "GFPGAN_53": {
                "x": 70.58390528851533,
                "y": -377.9857632240288
            },
            "OpenCvImageDecode_55": {
                "x": -1147.2532903999208,
                "y": -797.3999088258059
            },
            "OpenCvImageDecode_56": {
                "x": -1147.2532903999208,
                "y": -392.9307509307443
            },
            "OpenCvImageDecode_57": {
                "x": -1147.2532903999208,
                "y": -154.87362111794965
            },
            "OpenCvImageEncode_58": {
                "x": 409.77361380632794,
                "y": -510.25491746385427
            },
            "OpenCvImageEncode_59": {
                "x": 409.77361380632794,
                "y": -222.7857632240288
            },
            "InsightFaceAnalysis_60": {
                "x": -824.5577612465096,
                "y": -267.9601220291695
            },
            "InsightFaceAnalysis_61": {
                "x": -824.5577612465096,
                "y": -154.87362111794965
            }
        },
        "groups": []
    }
}